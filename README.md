# ğŸª¢ Proyecto de DetecciÃ³n de Saltos con Audio (VersiÃ³n Simplificada)

Este proyecto permite entrenar un modelo de IA para detectar saltos a la comba a partir de audio, utilizando un enfoque manual y directo para construir el dataset.

---

## ğŸ“ Estructura de carpetas

```
/data
  â”œâ”€â”€ raw/
  â”‚   â”œâ”€â”€ jumps/            # Audios donde SOLO hay saltos
  â”‚   â””â”€â”€ noise/            # Audios donde NO hay saltos (ruido de gimnasio, etc.)
  â”œâ”€â”€ classified/
  â”‚   â”œâ”€â”€ jump_segments/         # Fragmentos con salto (generados automÃ¡ticamente)
  â”‚   â””â”€â”€ non_jump_segments/     # Fragmentos sin salto
  â”œâ”€â”€ jump_data.csv         # CSV con los MFCCs y etiquetas
/models
  â”œâ”€â”€ jump_detection_model.pth   # Modelo entrenado
  â””â”€â”€ jump_detection_model.onnx  # VersiÃ³n exportada a ONNX (opcional)
```

---

## ğŸªœ Flujo de trabajo

### 1. ğŸ™ï¸ Graba tus audios
Coloca archivos `.wav` en las carpetas correspondientes:
- `data/raw/jumps/` â†’ grabaciones con saltos a la comba
- `data/raw/noise/` â†’ grabaciones sin saltos (ruido ambiente)

---

### 2. âœ‚ï¸ Ejecuta `split_audio.py`
Este script cortarÃ¡ cada audio en fragmentos de 1 segundo y los clasificarÃ¡ automÃ¡ticamente como salto o no salto segÃºn la carpeta de origen.

---

### 3. ğŸ§  Ejecuta `preprocess_data.py`
Este script extrae MFCCs (media y desviaciÃ³n estÃ¡ndar) de cada fragmento y genera `jump_data.csv` para entrenar.

---

### 4. ğŸ”¬ Ejecuta `train_model.py`
Entrena el modelo de detecciÃ³n de saltos. Guarda el modelo entrenado en `models/jump_detection_model.pth`.

---

### 5. (Opcional) ğŸ¤– Ejecuta `detect_jumps.py`
Clasifica nuevos fragmentos desconocidos usando el modelo entrenado (debes preparar la carpeta `data/filtered_segments/` con nuevos clips).

---

### 6. (Opcional) ğŸ“¦ Ejecuta `convert_to_onnx.py`
Convierte el modelo a formato ONNX si necesitas exportarlo fuera de Python.

---

## âœ… Requisitos

Instala las dependencias necesarias con:

```bash
pip install librosa torch pandas scikit-learn soundfile
```

---

## ğŸ“Œ Notas

- El modelo usa 26 caracterÃ­sticas por clip: 13 MFCC medios + 13 desviaciones estÃ¡ndar.
- Se recomienda tener al menos 100 fragmentos por clase para empezar a obtener resultados fiables.